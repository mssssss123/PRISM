@software{mei2025ultrarag,
  selected    = {true},
  title       = {UltraRAG v2: A Low-Code MCP Framework for Building Complex and Innovative RAG Pipelines},
  author      = {Sen Mei and Haidong Xin and Chunyi Peng and Yukun Yan and Others},
  booktitle = {OpenBMB},
  year        = {2025},
  month = aug,
  url         = {https://github.com/OpenBMB/UltraRAG},
  abstract    = {UltraRAG is a low-code, MCP-based framework designed to automate and standardize the construction of retrieval-augmented generation (RAG) pipelines. It supports custom pipeline definitions, complex iterative retrieval flows, and reproducible research workflows.},
  description = {A Low-Code MCP Framework for Building Complex and Innovative Retrieval-Augmented Generation systems.},
  preview={ultrarag.png},
  selected = {true},
  code = {https://github.com/OpenBMB/UltraRAG},
}

@inproceedings{li2024rag,
  title={RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards},
  author={Xinze Li* and Sen Mei* and Zhenghao Liu and Yukun Yan and Others},
  booktitle = {ICLR},
  abstract = {Retrieval-Augmented Generation (RAG) has proven its effectiveness in mitigating hallucinations in Large Language Models (LLMs) by retrieving knowledge from external resources. To adapt LLMs for the RAG systems, current approaches use instruction tuning to optimize LLMs, improving their ability to utilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses on equipping LLMs to handle diverse RAG tasks using different instructions. However, it trains RAG modules to overfit training signals and overlooks the varying data preferences among agents within the RAG system. In this paper, we propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG systems by aligning data preferences between different RAG modules. DDR works by collecting the rewards to optimize each agent in the RAG system with the rollout method, which prompts agents to sample some potential responses as perturbations, evaluates the impact of these perturbations on the whole RAG system, and subsequently optimizes the agent to produce outputs that improve the performance of the RAG system. Our experiments on various knowledge-intensive tasks demonstrate that DDR significantly outperforms the SFT method, particularly for LLMs with smaller-scale parameters that depend more on the retrieved knowledge. Additionally, DDR exhibits a stronger capability to align the data preference between RAG modules. The DDR method makes the generation module more effective in extracting key information from documents and mitigating conflicts between parametric memory and external knowledge.},
  description = {RAG-DDR is an end-to-end method that aligns RAG modules through data rewards, enabling LLMs to use retrieved knowledge more effectively than SFT.},
  year={2025},
  month= jan,
  preview={ddr.png},
  selected = {true},
  code = {https://github.com/OpenMatch/RAG-DDR},
}

@inproceedings{zhou2024marvel,
  title={MARVEL: unlocking the multi-modal capability of dense retrieval via visual module plugin},
  author={Zhou, Tianshuo* and Mei, Sen* and Li, Xinze and Liu, Zhenghao and Others},
  booktitle={ACL},
  pages={14608--14624},
  abstract = {This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL), which learns an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of the well-trained dense retriever, T5-ANCE, by incorporating the visual module's encoded image features as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and extracts the related text and image documents from anchor-linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. MARVEL provides an opportunity to broaden the advantages of text retrieval to the multi-modal scenario. Besides, we also illustrate that the language model has the ability to extract image semantics and partly map the image features to the input word embedding space.},
  description = {MARVEL learns an embedding space for queries and multi-modal documents to conduct retrieval and encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of the well-trained dense retriever, T5-ANCE, by incorporating the visual module's encoded image features as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and extracts the related text and image documents from anchor-linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. MARVEL provides an opportunity to broaden the advantages of text retrieval to the multi-modal scenario. Besides, we also illustrate that the language model has the ability to extract image semantics and partly map the image features to the input word embedding space.},
  year={2024},
  month = aug,
  preview={marvel.png},
  code = {https://github.com/OpenMatch/MARVEL},
}

@inproceedings{liu2023text,
  title={Text matching improves sequential recommendation by reducing popularity biases},
  author={Liu, Zhenghao* and Mei, Sen* and Xiong, Chenyan and Others},
  booktitle={CIKM},
  pages={1534--1544},
  year={2023},
  month = oct,
  abstract={This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users.},
  description={This work introduces TASTE, a text-matching sequential recommendation model that verbalizes items and interactions while using sparse attention to model long histories, achieving state-of-the-art performance and alleviating cold-start and popularity-bias issues.},
  preview={taste.png},
  code={https://github.com/OpenMatch/TASTE},
}

@inproceedings{chen2025clueanchor,
  title={ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation},
  author={Chen, Hao and Yan, Yukun and Mei, Sen and Che, Wanxiang and Others},
  booktitle={EMNLP},
  year={2025},
  month= nov,
  preview={clueanchor.png},
  abstract={Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge to improve factuality. However, existing RAG systems frequently underutilize the retrieved documents, failing to extract and integrate the key clues needed to support faithful and interpretable reasoning, especially in cases where relevant evidence is implicit, scattered, or obscured by noise. To address this issue, we propose ClueAnchor, a novel framework for enhancing RAG via clue-anchored reasoning exploration and optimization. ClueAnchor extracts key clues from retrieved content and generates multiple reasoning paths based on different knowledge configurations, optimizing the model by selecting the most appropriate reasoning path for the given context through reward-based preference optimization. Experiments show that ClueAnchor significantly outperforms prior RAG baselines in the completeness and robustness of reasoning. Further analysis confirms its strong resilience to noisy or partially relevant retrieved content, as well as its capability to identify supporting evidence even in the absence of explicit clue supervision during inference.},
  description={This work introduces ClueAnchor, a clue-anchored reasoning framework that generates and optimizes multiple reasoning paths to help RAG systems better extract and integrate key evidence, yielding more complete and robust reasoning even under noisy or implicit retrieval.},
  code={https://github.com/thunlp/ClueAnchor},
}

@inproceedings{xin2025lisrecmodelinguserpreferences,
  title={LISRec: Modeling User Preferences with Learned Item Shortcuts for Sequential Recommendation}, 
  author={Haidong Xin and Zhenghao Liu and Sen Mei and Ohters},
  booktitle={KDD},
  year={2026},
  month= aug,
  abstract={User-item interaction histories are pivotal for sequential recommendation systems but often include noise, such as unintended clicks or actions that fail to reflect genuine user preferences. To address this, we propose Learned Item Shortcuts for Sequential Recommendation (LISRec), a novel framework that explicitly captures stable preferences by extracting personalized semantic shortcuts from historical interactions. LISRec first learns task-agnostic semantic representations to assess item similarities, then constructs a personalized semantic graph over all user-interacted items. By identifying the maximal semantic connectivity subset within this graph, LISRec selects the most representative items as semantic shortcuts to guide user preference modeling. This focused representation filters out irrelevant actions while preserving the diversity of genuine interests. Experimental results on the Yelp and Amazon Product datasets illustrate that LISRec achieves a 13% improvement over baseline recommendation models, showing its effectiveness in capturing stable user interests. Further analysis indicates that shortcut-based histories better capture user preferences, making more accurate and relevant recommendations.},
  description={This work proposes LISRec, a framework that extracts personalized semantic shortcuts from user histories to filter noise and capture stable preferences, significantly improving sequential recommendation performance.},
  code={https://github.com/NEUIR/LISRec},
  preview={lisrec.png},
}